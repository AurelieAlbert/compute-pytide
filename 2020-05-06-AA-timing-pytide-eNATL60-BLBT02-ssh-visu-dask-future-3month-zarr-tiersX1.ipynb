{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/cnt0024/hmg2840/albert7a/DEV/git/conda-pack/pytide/lib/python3.6/site-packages/distributed/node.py:244: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 41576 instead\n",
      "  http_address[\"port\"], self.http_server.port\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:45686</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:41576/status' target='_blank'>http://127.0.0.1:41576/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>8</li>\n",
       "  <li><b>Cores: </b>56</li>\n",
       "  <li><b>Memory: </b>270.19 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:45686' processes=8 threads=56, memory=270.19 GB>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dask\n",
    "import dask.threaded\n",
    "import dask.multiprocessing\n",
    "from dask.distributed import Client\n",
    "\n",
    "client = Client()\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "print(len(client.scheduler_info()[\"workers\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zarr\n",
    "import netCDF4\n",
    "import pytide\n",
    "import xarray as xr\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 658 ms, sys: 82 ms, total: 740 ms\n",
      "Wall time: 1.82 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ds=xr.open_zarr('/store/albert7a/eNATL60/zarr/eNATL60-BLBT02-SSH-1h')\n",
    "ds_sorted=ds.sortby('time_counter')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_DATE = np.datetime64('2009-07-01')\n",
    "END_DATE = np.datetime64('2009-09-30')\n",
    "time_series=ds_sorted['time_counter']\n",
    "period = (time_series >= START_DATE) & (time_series <= END_DATE)\n",
    "time=time_series[period]\n",
    "ssh=ds_sorted.sossheig[period,:,0:2785]\n",
    "t=time.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.66 ms, sys: 0 ns, total: 1.66 ms\n",
      "Wall time: 972 Âµs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "wt = pytide.WaveTable()\n",
    "wt = pytide.WaveTable([\"M2\", \"S2\", \"N2\", \"O1\", \"K1\"])\n",
    "f, vu = wt.compute_nodal_modulations(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dask_array_rechunk(da, axis=0):\n",
    "    \"\"\"Search for the optimal block cutting without modifying the axis 'axis'\n",
    "    in order to optimize its access in memory.\"\"\"\n",
    "    nblocks = 1\n",
    "    \n",
    "    def calculate_chuncks_size(chunks, size):\n",
    "        result = np.array(chunks).prod() * size\n",
    "        return result / (1000**2)\n",
    "       \n",
    "    while True:\n",
    "        chunks = []\n",
    "        div = int(np.sqrt(nblocks))\n",
    "        for index, item in enumerate(da.chunks):\n",
    "            chunks.append(np.array(item).sum() * (div if index == axis else 1))\n",
    "        chunks = tuple(item // div for index, item in enumerate(chunks))\n",
    "        chuncks_size = calculate_chuncks_size(chunks, da.dtype.itemsize)\n",
    "        if chuncks_size > 100 and chuncks_size < 150:\n",
    "            return chunks\n",
    "        nblocks += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _apply_along_axis(arr, func1d, func1d_axis, func1d_args, func1d_kwargs):\n",
    "    \"\"\"Wrap apply_along_axis\"\"\"\n",
    "    return np.apply_along_axis(func1d, func1d_axis, arr, *func1d_args,\n",
    "                                  **func1d_kwargs)\n",
    "\n",
    "\n",
    "def apply_along_axis(func1d, axis, arr, *args, **kwargs):\n",
    "    \"\"\"Apply the harmonic analysis to 1-D slices along the given axis.\"\"\"\n",
    "    arr = dask.array.core.asarray(arr)\n",
    "\n",
    "    # Validate and normalize axis.\n",
    "    arr.shape[axis]\n",
    "    axis = len(arr.shape[:axis])\n",
    "\n",
    "    # Rechunk so that analyze is applied over the full axis.\n",
    "    arr = arr.rechunk(arr.chunks[:axis] + (arr.shape[axis:axis + 1], ) +\n",
    "                      arr.chunks[axis + 1:])\n",
    "\n",
    "    # Test out some data with the function.\n",
    "    test_data = np.ones(args[0].shape[1], dtype=arr.dtype)\n",
    "    test_result = np.array(func1d(test_data, *args, **kwargs))\n",
    "\n",
    "    # Map analyze over the data to get the result\n",
    "    # Adds other axes as needed.\n",
    "    result = arr.map_blocks(\n",
    "        _apply_along_axis,\n",
    "        name=dask.utils.funcname(func1d) + '-along-axis',\n",
    "        dtype=test_result.dtype,\n",
    "        chunks=(arr.chunks[:axis] + test_result.shape + arr.chunks[axis + 1:]),\n",
    "        drop_axis=axis,\n",
    "        new_axis=list(range(axis, axis + test_result.ndim, 1)),\n",
    "        func1d=func1d,\n",
    "        func1d_axis=axis,\n",
    "        func1d_args=args,\n",
    "        func1d_kwargs=kwargs,\n",
    "    )\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(720, 168, 298)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dask_array_rechunk(ssh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssh_rechunk = ssh.chunk(dask_array_rechunk(ssh))\n",
    "future = apply_along_axis(pytide.WaveTable.harmonic_analysis, 0, ssh_rechunk,\n",
    "                          *(f, vu))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "209271"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(future.dask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 25s, sys: 2min 59s, total: 7min 24s\n",
      "Wall time: 2h 14min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "analysis = future.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.61 s, sys: 8.2 s, total: 16.8 s\n",
      "Wall time: 22.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "amp_da=xr.DataArray(np.absolute(analysis),dims={'freq','y','x'},name='tidal-amp')\n",
    "amp_da.to_netcdf(path='/scratch/cnt0024/hmg2840/albert7a/eNATL60/eNATL60-BLBT02-S/1h/tide/pytide/eNATL60tiersX1-BLBT02_tidal_amp_y2009m07-m09.nc',engine='scipy')\n",
    "\n",
    "phase_da=xr.DataArray(np.angle(analysis),dims={'freq','y','x'},name='tidal-phase')\n",
    "phase_da.to_netcdf(path='/scratch/cnt0024/hmg2840/albert7a/eNATL60/eNATL60-BLBT02-S/1h/tide/pytide/eNATL60tiersX1-BLBT02_tidal_phase_y2009m07-m09.nc',engine='scipy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "nt=len(time)\n",
    "nwaves, ni, nj = analysis.shape\n",
    "for k in np.arange(len(time)):\n",
    "    ttide = wt.tide_from_mapping(\n",
    "    time[k].astype('datetime64[s]').astype('float64'),\n",
    "    analysis.reshape(nwaves, ni*nj)).reshape(ni, nj)\n",
    "    ttide_da=xr.DataArray(ttide,dims={'y','x'},name='tide')\n",
    "    ttide_da.to_netcdf(path='/scratch/cnt0024/hmg2840/albert7a/eNATL60/eNATL60-BLBT02-S/1h/tide/pytide/eNATL60tiersX1-BLBT02_tide_y2009m07-m09_k'+str(k)+'.nc',engine='scipy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytide",
   "language": "python",
   "name": "pytide"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
